{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32b112b-7109-4200-b222-0d7e21e5b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from glob import glob\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage.feature import hog\n",
    "from joblib import dump, load\n",
    "import PIL\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import time\n",
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Use CPU only\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c618a5-26ab-4abc-b426-dc59452513ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Validation_data/data.csv\")\n",
    "svc = load('svc_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aabe2301-ffb7-4fae-8062-3074cd7878ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "model_openvino = core.read_model(model=\"model.xml\")\n",
    "compiled_model = core.compile_model(model=model_openvino, device_name=\"CPU\")\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7daf9e2-2d58-4c0d-a657-a7c016495d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toBool(img):\n",
    "    pillow = PIL.Image.fromarray(img)\n",
    "    return np.asarray(pillow.point(lambda x: 0 if x < 128 else 1, mode='1'))\n",
    "def crop(img_path):\n",
    "    img =  toBool(np.asarray(PIL.Image.open(img_path)))\n",
    "    canvas = img.copy()\n",
    "    ractangle_x_size = 50\n",
    "    ractangle_y_size = 50\n",
    "    shape = img.shape\n",
    "    i_indexes = []\n",
    "    j_indexes = []\n",
    "    for i in range(0,shape[1],ractangle_x_size):\n",
    "        for j in range(0,shape[0],ractangle_y_size):\n",
    "            ractangle = [[i,j],[i+ractangle_x_size,j+ractangle_y_size]]\n",
    "            cut_img = img[ractangle[0][1]:ractangle[1][1],ractangle[0][0]:ractangle[1][0]]\n",
    "            cut_img = cut_img.reshape(cut_img.shape[0]*cut_img.shape[1])\n",
    "            if(svc.predict([cut_img])[0]>0.5):\n",
    "                i_indexes.append(i)\n",
    "                j_indexes.append(j)\n",
    "    return canvas[min(j_indexes):max(j_indexes)+ractangle_y_size,min(i_indexes):max(i_indexes)+ractangle_x_size]\n",
    "max_len=25\n",
    "def decode_batch_of_1(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_len\n",
    "    ]\n",
    "\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text[0].replace(\"[UNK]\",\"\")\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "characters = ['a', 'ą', 'b', 'c', 'ć', 'd', 'e', 'ę', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'ł',\n",
    "              'm', 'n', 'ń', 'o', 'ó', 'p', 'r', 's', 'ś', 't', 'u', 'w', 'y', 'z', 'ź', 'ż',' ']\n",
    "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=list(characters), mask_token=None, invert=True,num_oov_indices=1\n",
    ")\n",
    "img_height = 128\n",
    "img_width = 496\n",
    "def encode_single_sample(img_path):\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    # 5. Transpose the image because we want the time\n",
    "    # dimension to correspond to the width of the image.\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    # 6. Map the characters in label to numbers\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ebb54fd-d773-42bd-a85f-378eafe95ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "Accuracy:  0.469\n",
      "Average similarity:  0.9411408277617281\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "similarity = 0\n",
    "sample_amount = 1000\n",
    "for i in range(sample_amount):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    img = crop(df[\"Img_path\"].iloc[i])\n",
    "    pil = PIL.Image.fromarray(img)\n",
    "    pil.save(\"temp/temp.jpg\")\n",
    "    img = encode_single_sample(\"temp/temp.jpg\")\n",
    "    label_pred = compiled_model([np.array([img])])[output_layer]\n",
    "    label_pred = decode_batch_of_1(label_pred)\n",
    "    label = df[\"Name\"].iloc[i] + \" \"+ df[\"Surname\"].iloc[i]\n",
    "    label = label.lower()\n",
    "    if label==label_pred:\n",
    "        acc+=1\n",
    "    similarity+= similar(label,label_pred)\n",
    "print(\"Accuracy: \",acc/sample_amount)\n",
    "print(\"Average similarity: \",similarity/sample_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b35f7-4b2d-4448-88d1-2c3acb1dbe5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
